{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bb51ab7-bfe6-4ac9-bb88-e79da6724f15",
   "metadata": {},
   "source": [
    "# Build Dataset\n",
    "In this notebook the build dataset function, needed for the datapipeline is implemented\n",
    "\n",
    "This notebook is inspired by and partly copied from https://www.kaggle.com/code/wengsilu/birdclef24pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f906eb-9e34-4629-b167-dd9f881de0c3",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7afaf862-698e-4a57-8be5-70405efb5068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 17:12:49.105491: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-01 17:12:49.105647: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-01 17:12:49.106922: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-01 17:12:49.115654: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-01 17:12:50.015851: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "from IPython.display import Audio\n",
    "\n",
    "import tensorflow as tf\n",
    "# Set logging level to avoid unnecessary messages\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "# Set autograph verbosity to avoid unnecessary messages\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "import tensorflow_io as tfio\n",
    "import tensorflow_extra as tfe\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b36eb19-b2c3-4c8e-9d91-db6c575346a9",
   "metadata": {},
   "source": [
    "## Set device and strategy\n",
    "If GPUs are available, use them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42bb9e50-3854-4eb3-ad3c-3f4863a38aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "> Running on GPU | Num of GPUs:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 17:12:51.412055: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-01 17:12:51.443164: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-01 17:12:51.443723: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-01 17:12:51.445597: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-01 17:12:51.446128: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-01 17:12:51.446681: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-01 17:12:51.683828: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-01 17:12:51.684225: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-01 17:12:51.684243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-07-01 17:12:51.684593: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-01 17:12:51.684621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4084 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "#tf.config.set_visible_devices([], 'GPU')\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "gpus = tf.config.list_logical_devices('GPU')\n",
    "ngpu = len(gpus) # Check number of GPUs\n",
    "if ngpu:\n",
    "    # Set GPU strategy\n",
    "    strategy = tf.distribute.MirroredStrategy(gpus) # single-GPU or multi-GPU\n",
    "    # Print GPU details\n",
    "    print(\"> Running on GPU\", end=' | ')\n",
    "    print(\"Num of GPUs: \", ngpu)\n",
    "    device='GPU'\n",
    "else:\n",
    "    # If no GPUs are available, use CPU\n",
    "    print(\"> Running on CPU\")\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    device='CPU'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ca1658-1c69-4840-a901-51befa49726f",
   "metadata": {},
   "source": [
    "## Load dataframe (for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bf89a5e-7741-4595-bd97-8d348211ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/dataset10.csv\")\n",
    "df[\"fullfilename\"] = \"../\" + df[\"fullfilename\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c977d38d-bb78-4295-8d68-cffe4c613b7a",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e76e8f20-32fd-4cbc-a136-e2099dd061e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cfg:\n",
    "    # random seed\n",
    "    seed = 42\n",
    "\n",
    "    # audio clip settings\n",
    "    sr = 24000\n",
    "    duration = 15 # the duration of the clips\n",
    "    desired_length = duration*sr\n",
    "    \n",
    "    n_samples = duration*sr\n",
    "    hop_length = 2048 # \"stepsize\" of the fft for the melspectrograms\n",
    "    nfft = 4096 # windowsize of the fft for the melspectrograms\n",
    "    n_mels = 128 # number of mel frequency bins\n",
    "    fmax = sr/2 # maximum frequency in the melspectrograms\n",
    "    input_dim = (int(duration*sr/hop_length + 1), n_mels)\n",
    "    \n",
    "    # data processing settings\n",
    "    batch_size = 16\n",
    "    shuffle_buffer = 256 # idk Number of elements from the dataset to buffer for shuffling.\n",
    "    \n",
    "    # class labels/names\n",
    "    names = list(np.unique(df.en))\n",
    "    num_classes = len(names)\n",
    "    labels = list(range(num_classes))\n",
    "    label2name = dict(zip(labels, names))\n",
    "    name2label = {v:k for k,v in label2name.items()}\n",
    "\n",
    "    # set device\n",
    "    device = device\n",
    "\n",
    "# set random seed in keras\n",
    "tf.keras.utils.set_random_seed(cfg.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8d8eb7-20a8-423c-a746-ada546b0f9cd",
   "metadata": {},
   "source": [
    "# Function to load and prepare audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab51a511-a5c7-41a2-ac7e-eb5aa48ca89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_files(df):\n",
    "    drop_indices = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        filepath = df.iloc[i].fullfilename\n",
    "        try:\n",
    "            audio = tfio.audio.AudioIOTensor(filepath, dtype = tf.float32) # lazy load the file\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading audio file {filepath} with TensorFlow I/O: {e}\")\n",
    "            print(\"Deleting file from dataframe.\")\n",
    "            drop_indices.append(i)\n",
    "        if audio.shape[0] == 0:\n",
    "            print(f\"Failed to load audio file {filepath} with TensorFlow I/O: shape[0] = 0\")\n",
    "            print(\"Deleting file from dataframe.\")\n",
    "            drop_indices.append(i)\n",
    "    df.drop(index = drop_indices, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87fc9f9b-bd5b-49b8-b526-bbf07fae04c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/300 [00:00<?, ?it/s]2024-07-01 17:12:51.959272: I tensorflow_io/core/kernels/cpu_check.cc:128] Your CPU supports instructions that this TensorFlow IO binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2024-07-01 17:12:51.966171: W tensorflow_io/core/kernels/audio_video_mp3_kernels.cc:271] libmp3lame.so.0 or lame functions are not available\n",
      " 57%|█████████████████████████████████████████████▉                                   | 170/300 [00:03<00:01, 66.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load audio file ../../data/dataset10/Troglodytes troglodytes_Eurasian Wren/XC845049.mp3 with TensorFlow I/O: shape[0] = 0\n",
      "Deleting file from dataframe.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|█████████████████████████████████████████████████████████████████▌               | 243/300 [00:04<00:00, 62.85it/s]2024-07-01 17:12:56.384855: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at audio_kernels.cc:130 : OUT_OF_RANGE: Read less bytes than requested\n",
      " 87%|██████████████████████████████████████████████████████████████████████▍          | 261/300 [00:04<00:00, 73.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading audio file ../../data/dataset10/Luscinia megarhynchos_Common Nightingale/XC899978.mp3 with TensorFlow I/O: {{function_node __wrapped__IO>AudioReadableInit_device_/job:localhost/replica:0/task:0/device:CPU:0}} Read less bytes than requested [Op:IO>AudioReadableInit]\n",
      "Deleting file from dataframe.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 300/300 [00:05<00:00, 56.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "check_files(df)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c6b3e5d-5021-4b96-8f2d-8dcd5d378b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates random integer # from https://www.kaggle.com/code/wengsilu/birdclef24pretraining\n",
    "def random_int(shape=[], minval=0, maxval=1):\n",
    "    return tf.random.uniform(shape=shape, minval=minval, maxval=maxval, dtype=tf.int32)\n",
    "\n",
    "# Generats random float\n",
    "def random_float(shape=[], minval=0.0, maxval=1.0):\n",
    "    rnd = tf.random.uniform(shape=shape, minval=minval, maxval=maxval, dtype=tf.float32)\n",
    "    return rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63f987fa-8236-4913-b584-60eafb3ff69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_loader(with_labels = True, cfg = cfg, num_classes = cfg.num_classes):\n",
    "    #def slow_load(filepath):\n",
    "    #    audio, sr = librosa.load(filepath, sr = cfg.sr)\n",
    "    #    # randomly pad clip if shorter\n",
    "    #    if len(audio) < cfg.duration*sr:\n",
    "    #        _ = np.zeros(window*sr)\n",
    "    #        rdm = random_int(maxval = cfg.duration*sr-len(audio))\n",
    "    #        _[rdm:rdm + len(audio)] = audio\n",
    "    #        audio = _\n",
    "    #    else: # select random window if clip longer\n",
    "    #        rdm = random_int(maxval = len(audio) - cfg.duration*sr)\n",
    "    #        audio = audio[rdm:rdm + cfg.duration*sr]\n",
    "    #    audio = tf.convert_to_tensor(audio, dtype = tf.float32)\n",
    "    #    return audio\n",
    "    \n",
    "    def decode(filepath):\n",
    "        # read audio\n",
    "        #try:\n",
    "        audio = tfio.audio.AudioIOTensor(filepath, dtype = tf.float32) # lazy load the file\n",
    "        #except Exception as e:\n",
    "        #    print(f\"Error loading audio file {filepath} with TensorFlow I/O: {e}\")\n",
    "        #    print(\"Proceeding to slow load file\")\n",
    "        #    return slow_load(filepath)\n",
    "        #if audio.shape[0] == 0:\n",
    "        #    print(f\"Failed to load audio file {filepath.numpy} with TensorFlow I/O: shape[0] = 0\")\n",
    "        #    print(\"Proceeding to slow load file\")\n",
    "        #    return slow_load(filepath)\n",
    "        \n",
    "        rate = audio.rate\n",
    "        # cut out clip of specified duration at random position\n",
    "        num_samples = cfg.duration*rate\n",
    "        length = tf.cast(audio.shape[0], tf.int32)\n",
    "        if num_samples < length:\n",
    "            rdm = random_int(maxval = length - num_samples)\n",
    "            audio = audio[rdm:rdm+num_samples]\n",
    "        else:\n",
    "            audio = audio.to_tensor()\n",
    "        audio = tf.cast(audio, tf.float32)\n",
    "        # resample if necessary\n",
    "        audio = tfio.audio.resample(audio, tf.cast(rate, tf.int64), cfg.sr) if rate != cfg.sr else audio\n",
    "        # remove noise (tfio.audio.split() or tfio.audio.trim()?)# can't do this when the clip is already cut\n",
    "        # stereo to mono\n",
    "        audio = tf.reduce_mean(audio, axis=-1) if tf.shape(audio)[-1] == 2 else tf.squeeze(audio, axis = -1)\n",
    "        # pad if necessary\n",
    "        if tf.size(audio) < cfg.desired_length:\n",
    "            missing = cfg.desired_length - tf.size(audio)\n",
    "            rdm = random_int(maxval = missing)\n",
    "            audio = tf.pad(audio, [[rdm, missing-rdm]]) # pad rdm zeros left and missing-rdm zeros rigth\n",
    "        audio = tf.reshape(audio, [cfg.sr*cfg.duration])\n",
    "        return audio\n",
    "\n",
    "    def get_target(target):          \n",
    "        target = tf.reshape(target, [1])\n",
    "        target = tf.cast(tf.one_hot(target, num_classes), tf.float32) \n",
    "        target = tf.reshape(target, [num_classes])\n",
    "        return target\n",
    "    \n",
    "    def decode_with_labels(path, label):\n",
    "        label = get_target(label)\n",
    "        return decode(path), label\n",
    "\n",
    "    return decode_with_labels if with_labels else decode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658d40ec-8c8e-4fcd-80fd-41b848d999e9",
   "metadata": {},
   "source": [
    "# Build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d6a7964-8df2-4441-993d-6005fdad919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(paths, labels=None, batch_size=cfg.batch_size,\n",
    "                  audio_decode_fn=None,\n",
    "                  num_classes=cfg.num_classes,\n",
    "                  cache=False, cache_dir=\"\", drop_remainder=False,\n",
    "                  repeat=True, shuffle=cfg.shuffle_buffer):\n",
    "    \"\"\"\n",
    "    Creates a TensorFlow dataset from the given paths and labels.\n",
    "    \n",
    "    Args:\n",
    "        paths (list): A list of file paths to the audio files.\n",
    "        labels (list): A list of corresponding labels for the audio files.\n",
    "        batch_size (int): Batch size for the created dataset.\n",
    "        audio_decode_fn (function): A function to decode the audio file.\n",
    "        cache (bool): Whether to cache the dataset or not.\n",
    "        cache_dir (str): Directory path to cache the dataset.\n",
    "        drop_remainder (bool): Whether to drop the last batch if it is smaller than batch_size.\n",
    "        repeat (bool): Whether to repeat the dataset or not.\n",
    "        shuffle (int): Number of elements from the dataset to buffer for shuffling.\n",
    "        \n",
    "    Returns:\n",
    "        ds (tf.data.Dataset): A TensorFlow dataset.\n",
    "    \"\"\"\n",
    "    # Create cache directory if cache is enabled\n",
    "    if cache_dir != \"\" and cache is True:\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "    # Set default audio decode function if not provided\n",
    "    if audio_decode_fn is None:\n",
    "        audio_decode_fn = audio_loader(with_labels = labels is not None, cfg = cfg, num_classes = cfg.num_classes)\n",
    "        \n",
    "    # Set TensorFlow AUTOTUNE option\n",
    "    AUTO = tf.data.experimental.AUTOTUNE # hopefully optimizes data pipeline and decreases loading times\n",
    "    # Create slices based on whether labels are provided\n",
    "    slices = (paths,) if labels is None else (paths, labels)\n",
    "    # Create TensorFlow dataset from slices\n",
    "    ds = tf.data.Dataset.from_tensor_slices(slices)\n",
    "    # Map audio decode function to dataset\n",
    "    ds = ds.map(audio_decode_fn, num_parallel_calls=AUTO)\n",
    "    # Cache dataset in memory if cache is enabled\n",
    "    ds = ds.cache(cache_dir) if cache else ds\n",
    "    # Repeat dataset indefinitely if repeat is enabled\n",
    "    ds = ds.repeat() if repeat else ds\n",
    "    # Create TensorFlow dataset options\n",
    "    opt = tf.data.Options()\n",
    "    # Shuffle dataset if shuffle is enabled\n",
    "    if shuffle: \n",
    "        ds = ds.shuffle(shuffle, seed=cfg.seed)\n",
    "        opt.experimental_deterministic = False\n",
    "    #if cfg.device=='GPU':\n",
    "    #    # If the device is a GPU, turn off auto-sharding to avoid performance issues\n",
    "    #    opt.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
    "    # Set the options for the dataset\n",
    "    ds = ds.with_options(opt)\n",
    "    # Batch the dataset with the specified batch size\n",
    "    ds = ds.batch(batch_size, drop_remainder=drop_remainder)\n",
    "    # Prefetch the next batch of data to improve performance\n",
    "    ds = ds.prefetch(AUTO)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c81ce81-cffe-4d06-bf41-54bebf06305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sample = df.sample(frac=0.2, replace=False, random_state=cfg.seed)\n",
    "#paths = df_sample.fullfilename.tolist()\n",
    "#names = df_sample.en.tolist()\n",
    "#labels = []\n",
    "#for name in names:\n",
    "#    labels.append(cfg.name2label[name])\n",
    "#\n",
    "#ds = build_dataset(paths, labels, cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98d6b3c9-19ed-42c2-830e-04fc8c24797e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def plot_batch(batch, row=3, col=3, label2name=None,):\n",
    "#    \"\"\"Plot one batch data\"\"\"\n",
    "#    if isinstance(batch, tuple) or isinstance(batch, list):\n",
    "#        audios, tars = batch\n",
    "#    else:\n",
    "#        audios = batch\n",
    "#        tars = None\n",
    "#    plt.figure(figsize=(col*5, row*3))\n",
    "#    for idx in range(row*col):\n",
    "#        ax = plt.subplot(row, col, idx+1)\n",
    "#        plt.plot(audios[idx].numpy(), color=cmap(0.1))\n",
    "#        if tars is not None:\n",
    "#            label = tars[idx].numpy().argmax()\n",
    "#            name = label2name[label]\n",
    "#            plt.title(name)\n",
    "#    plt.tight_layout()\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa4d7dfa-7f5b-43c8-a5c8-3688367562ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b648820-e411-4bce-8c12-134fa717c86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#audios, labels = next(iter(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f846135-c75c-4d7c-930b-82f0bbb98880",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_batch((audios, labels), label2name=cfg.label2name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7edd9521-800e-4e1d-85d2-4371b63d696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Input\n",
    "\n",
    "melspec_layer = tfe.layers.MelSpectrogram(n_fft=cfg.nfft, \n",
    "                                          hop_length=cfg.hop_length, \n",
    "                                          sr=cfg.sr, \n",
    "                                          fmin=0,\n",
    "                                          fmax=cfg.fmax,\n",
    "                                         )\n",
    "\n",
    "class ExpandDimsLayer(Layer):\n",
    "    def __init__(self, axis, **kwargs):\n",
    "        super(ExpandDimsLayer, self).__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.expand_dims(inputs, axis=self.axis)\n",
    "\n",
    "zscore_layer = tfe.layers.ZScoreMinMax()\n",
    "\n",
    "def build_model():\n",
    "    inp = Input(shape=(cfg.n_samples,))\n",
    "    \n",
    "    # Spectrogram\n",
    "    x = melspec_layer(inp)\n",
    "    \n",
    "    # Normalize\n",
    "    x = zscore_layer(x)\n",
    "    \n",
    "    # Add a channel dimension\n",
    "    x = ExpandDimsLayer(axis=-1)(x)\n",
    "    \n",
    "    # Base model\n",
    "    x = Conv2D(32, kernel_size=(3, 3), padding='valid', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding=\"valid\")(x)\n",
    "    x = Conv2D(64, kernel_size=(3, 3), padding='valid', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding=\"valid\")(x)\n",
    "    #x = Dropout(0.4)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    #x = Dropout(0.25)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    output = Dense(cfg.num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=output, name = \"Basemodel\")\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4d9f166-8fd3-42e0-9970-698b4a4c51c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Basemodel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 360000)]          0         \n",
      "                                                                 \n",
      " mel_spectrogram (MelSpectr  (None, 128, 176)          0         \n",
      " ogram)                                                          \n",
      "                                                                 \n",
      " z_score_min_max (ZScoreMin  (None, 128, 176)          0         \n",
      " Max)                                                            \n",
      "                                                                 \n",
      " expand_dims_layer (ExpandD  (None, 128, 176, 1)       0         \n",
      " imsLayer)                                                       \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 126, 174, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 63, 87, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 85, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 30, 42, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 80640)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                5161024   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5182250 (19.77 MB)\n",
      "Trainable params: 5182250 (19.77 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fe8191c-25a3-43cf-87eb-f4c1397dacb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "id_train, id_val, y_train, y_val = train_test_split(range(len(df)), df[\"en\"].to_list(), test_size = 0.3, random_state = cfg.seed)\n",
    "\n",
    "paths_train = list(df.iloc[id_train].fullfilename)\n",
    "paths_val = list(df.iloc[id_val].fullfilename)\n",
    "\n",
    "label_train = []\n",
    "for y in y_train:\n",
    "    label_train.append(cfg.name2label[y])\n",
    "label_val = []\n",
    "for y in y_val:\n",
    "    label_val.append(cfg.name2label[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7bba49c-cfde-46b2-b003-986fe56860d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 17:12:59.368402: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "train_ds = build_dataset(paths_train, label_train)\n",
    "valid_ds = build_dataset(paths_val, label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8112d71-fb8c-4a02-9459-1de359068494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 360000), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0c61e1-ca22-4d63-be4a-4e3db2e5d869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "#try:\n",
    "history = model.fit(\n",
    "    train_ds, \n",
    "    epochs=2, \n",
    "    validation_data=valid_ds,\n",
    "    steps_per_epoch=int(len(paths_train)/cfg.batch_size)\n",
    ")\n",
    "#except Exception as e:\n",
    "#    print(f\"Ich will nicht mehr: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07d2901-1fcd-411f-b6ab-a51af6b9e183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slow_load(filepath):\n",
    "    audio, sr = librosa.load(filepath, sr = cfg.sr)\n",
    "     # randomly pad clip if shorter\n",
    "    if len(audio) < cfg.duration*sr:\n",
    "        _ = np.zeros(window*sr)\n",
    "        rdm = random_int(maxval = cfg.duration*sr-len(audio))\n",
    "        _[rdm:rdm + len(audio)] = audio\n",
    "        audio = _\n",
    "    else: # select random window if clip longer\n",
    "        rdm = random_int(maxval = len(audio) - cfg.duration*sr)\n",
    "        audio = audio[rdm:rdm + cfg.duration*sr]\n",
    "    audio = tf.convert_to_tensor(audio, dtype = tf.float32)\n",
    "    return audio\n",
    "    \n",
    "def decode(filepath):\n",
    "        # read audio\n",
    "        try:\n",
    "            audio = tfio.audio.AudioIOTensor(filepath, dtype = tf.float32) # lazy load the file\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading audio file {filepath} with TensorFlow I/O: {e}\")\n",
    "            print(\"Proceeding to slow load file\")\n",
    "            return slow_load(filepath)\n",
    "        if audio.shape[0] == 0:\n",
    "            print(\"Failed to load audio with TensorFlow I/O: shape[0] = 0\")\n",
    "            print(\"Proceeding to slow load file\")\n",
    "            return slow_load(filepath)\n",
    "        rate = audio.rate\n",
    "        # cut out clip of specified duration at random position\n",
    "        num_samples = cfg.duration*rate\n",
    "        length = tf.cast(audio.shape[0], tf.int32)\n",
    "        if num_samples < length:\n",
    "            rdm = random_int(maxval = length - num_samples)\n",
    "            audio = audio[rdm:rdm+num_samples]\n",
    "        else:\n",
    "            audio = audio.to_tensor()\n",
    "        audio = tf.cast(audio, tf.float32)\n",
    "        # resample if necessary\n",
    "        audio = tfio.audio.resample(audio, tf.cast(rate, tf.int64), cfg.sr) if rate != cfg.sr else audio\n",
    "        # remove noise (tfio.audio.split() or tfio.audio.trim()?)# can't do this when the clip is already cut\n",
    "        # stereo to mono\n",
    "        audio = tf.reduce_mean(audio, axis=-1) if tf.shape(audio)[-1] == 2 else tf.squeeze(audio, axis = -1)\n",
    "        # pad if necessary\n",
    "        if tf.size(audio) < cfg.desired_length:\n",
    "            missing = cfg.desired_length - tf.size(audio)\n",
    "            rdm = random_int(maxval = missing)\n",
    "            audio = tf.pad(audio, [[rdm, missing-rdm]]) # pad rdm zeros left and missing-rdm zeros rigth\n",
    "        #audio = tf.reshape(audio, [cfg.sr*cfg.duration])\n",
    "        return audio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7b8cf5-4e81-467e-98a6-78b2be923e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in tqdm(paths_train):\n",
    "    audio = decode(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21773b67-6f7c-49fd-bc05-9fdf1202f503",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = slow_load(paths_train[71]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7ddb0c-f92f-4809-b131-7d655a91af39",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b0e260-00f1-4569-b886-e77b813796df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data = audio, rate = cfg.sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec9bf8b-c9e9-45c7-bdce-588cb6e8edff",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = decode(paths_train[71]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdf599c-b9c3-464c-8bc4-077fcc41b621",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16663b8c-adf7-4bef-8a16-4aad8ff2e5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio(filepath):\n",
    "    file_bytes = tf.io.read_file(filepath)\n",
    "    audio = tfio.audio.decode_wav(file_bytes, dtype=tf.int64) # decode .mp3 file\n",
    "    audio = tf.cast(audio, tf.float32)\n",
    "    if tf.shape(audio)[1]>1: # stereo -> mono\n",
    "        audio = audio[...,0:1]\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63be184c-c350-4467-b1ff-7a042c86a8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import mutagen\n",
    "\n",
    "# Using pydub\n",
    "#audio = AudioSegment.from_file(paths_train[81])\n",
    "#print(f\"Channels: {audio.channels}, Frame Rate: {audio.frame_rate}\")\n",
    "\n",
    "# Using mutagen\n",
    "mp3_info = mutagen.File(paths_train[71], easy=True)\n",
    "print(mp3_info.info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
