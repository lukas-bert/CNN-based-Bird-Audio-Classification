# set paths of repository and storage folder (for files)

path_storage = "../data/"
dataset_name = "dataset"

rule download_dataset:
    input: 
        script = "scripts/download_dataset.py",
        config = "resources/config_" + dataset_name + ".json"
    output: 
        path_storage + dataset_name + "_raw.csv"
    shell: 
        "python {input.script} {path_storage} {dataset_name} {input.config}" # overwrite existing folder with '-o' flag

rule get_spectrograms:
    input: 
        script = "scripts/compute_spectrograms.py",
        config = "resources/config.json",
       # dataframe = path_storage + dataset_name + "_raw.csv"
    output: 
        path_storage + dataset_name + "_train.csv",
        path_storage + dataset_name + "_test.csv"
    shell: 
        "python {input.script} '../data/dataset_raw.csv' {input.config}" 

rule get_audio_features:
    input: 
        script = "scripts/audio_features.py",
        dataframe = path_storage + dataset_name + "_t{rain_est}.csv"
    output: 
        path_storage + dataset_name + "_t{rain_est}_features.csv"
    threads: 16
    shell: 
        "python {input.script} {input.dataframe}"

rule train_model:
    input: 
        script = "scripts/train.py",
        config = "resources/config.json",
        dataframe = path_storage + dataset_name + "_train.csv"
    output: 
        model = "models/v3_final_model_5.keras"
    shell: 
        "python {input.script} {input.dataframe} {input.config} 'models/v3_final_model'"

# execute all required rules
rule all:   
    input: 
        path_storage + dataset_name + "_train.csv",
        path_storage + dataset_name + "_test_features.csv",
        "models/v3_final_model_5.keras"

